{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4).Eye_Gaze_Detection2\n",
    "\n",
    "We will learn how to detect the gaze, and more specifically to detect if the eyes are looking to the left, the right or the center.\n",
    "\n",
    "<img src=\"picture/eyes.png\">\n",
    "\n",
    "\n",
    "Looking at the image above, it’s that the sclera (white part of the eye) fills the right part of the eye when the eye is looking at the left, the opposite happens when it’s looking to the right and when it’s looking to the center the white is well balanced between left and right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "from math import hypot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we used the detector to detect the frontal face\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# it will dectect the facial landwark points \n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "font = cv2.FONT_HERSHEY_PLAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We create a function that we will need later on to detect the medium point.\n",
    "#On this function we simply put the coordinates of two points and will return the medium point \n",
    "#(the points in the middle between the two points).\n",
    "def midpoint(p1 ,p2):\n",
    "    return int((p1.x + p2.x)/2), int((p1.y + p2.y)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blinking_ratio(eye_points, facial_landmarks):\n",
    "    \n",
    "    #to detect the left_side of a left eye\n",
    "    left_point = (facial_landmarks.part(eye_points[0]).x, facial_landmarks.part(eye_points[0]).y)\n",
    "    \n",
    "    #to detect the right_side of the left eye\n",
    "    right_point = (facial_landmarks.part(eye_points[3]).x, facial_landmarks.part(eye_points[3]).y)\n",
    "    \n",
    "    #to detect the mid point for the center of top in left eye\n",
    "    center_top = midpoint(facial_landmarks.part(eye_points[1]), facial_landmarks.part(eye_points[2]))\n",
    "    \n",
    "    #to detect the mid point for the center of the bottom in left eye\n",
    "    center_bottom = midpoint(facial_landmarks.part(eye_points[5]), facial_landmarks.part(eye_points[4]))\n",
    "    \n",
    "    #to calculate horizontal line distance\n",
    "    hor_line_lenght = hypot((left_point[0] - right_point[0]), (left_point[1] - right_point[1]))\n",
    "    \n",
    "    #to calculate vertical line distance\n",
    "    ver_line_lenght = hypot((center_top[0] - center_bottom[0]), (center_top[1] - center_bottom[1]))\n",
    "    \n",
    "    #to calculate ratio\n",
    "    ratio = hor_line_lenght / ver_line_lenght\n",
    "    \n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eye_Gaze_Ratio\n",
    "\n",
    "The idea is to split the eye in two parts and to find out in which of the two parts there is more sclera visible.\n",
    "\n",
    "<img src=\"picture/eye_division.png\">\n",
    "\n",
    "If the sclera is more visible on the right part, so the eye is looking at the left (our left) like in this case.\n",
    "\n",
    "Technically to detect the sclera we convert the eye into grayscale, we find a treshold and we count the white pixels.\n",
    "\n",
    "The gaze ratio tells use where a specific eye is looking.\n",
    "Normally both the eyes look in the same direction, so if we correctly detect the gaze of a single eye, we detect the gaze of both eyes.\n",
    "\n",
    "Only if we want to be more precise we could detect the gaze of both the eyes and use both values to detect the gaze ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gaze_ratio(eye_points,facial_landmarks):\n",
    "    # Gaze detection\n",
    "        #getting the area from the frame of the left eye only\n",
    "        left_eye_region = np.array([(facial_landmarks.part(eye_points[0]).x, facial_landmarks.part(eye_points[0]).y),\n",
    "                            (facial_landmarks.part(eye_points[1]).x, facial_landmarks.part(eye_points[1]).y),\n",
    "                            (facial_landmarks.part(eye_points[2]).x, facial_landmarks.part(eye_points[2]).y),\n",
    "                            (facial_landmarks.part(eye_points[3]).x, facial_landmarks.part(eye_points[3]).y),\n",
    "                            (facial_landmarks.part(eye_points[4]).x, facial_landmarks.part(eye_points[4]).y),\n",
    "                            (facial_landmarks.part(eye_points[5]).x, facial_landmarks.part(eye_points[5]).y)], np.int32)\n",
    "        \n",
    "        #cv2.polylines(frame, [left_eye_region], True, 255, 2)\n",
    "        height, width, _ = frame.shape\n",
    "    \n",
    "        #create the mask to extract xactly the inside of the left eye and exclude all the sorroundings.\n",
    "        mask = np.zeros((height, width), np.uint8)\n",
    "        cv2.polylines(mask, [left_eye_region], True, 255, 2)\n",
    "        cv2.fillPoly(mask, [left_eye_region], 255)\n",
    "        eye = cv2.bitwise_and(gray,gray,mask = mask)\n",
    "        \n",
    "        #We now extract the eye from the face and we put it on his own window.Onlyt we need to keep in mind that wecan only cut\n",
    "        #out rectangular shapes from the image, so we take all the extremes points of the eyes to get the rectangle\n",
    "        min_x = np.min(left_eye_region[:, 0])\n",
    "        max_x = np.max(left_eye_region[:, 0])\n",
    "        min_y = np.min(left_eye_region[:, 1])\n",
    "        max_y = np.max(left_eye_region[:, 1])\n",
    "        gray_eye = eye[min_y: max_y, min_x: max_x]\n",
    "        \n",
    "        #threshold to seperate iris and pupil from the white part of the eye.\n",
    "        _, threshold_eye = cv2.threshold(gray_eye, 70, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        #dividing the eye into 2 parts .left_side and right_side.\n",
    "        height, width = threshold_eye.shape\n",
    "        left_side_threshold = threshold_eye[0: height, 0: int(width / 2)]\n",
    "        left_side_white = cv2.countNonZero(left_side_threshold)\n",
    "        right_side_threshold = threshold_eye[0: height, int(width / 2): width]\n",
    "        right_side_white = cv2.countNonZero(right_side_threshold)\n",
    "        \n",
    "        if left_side_white == 0:\n",
    "            gaze_ratio = 1\n",
    "            \n",
    "        elif right_side_white == 0:\n",
    "            gaze_ratio = 5\n",
    "            \n",
    "        else:\n",
    "            gaze_ratio = left_side_white / right_side_white\n",
    "        return(gaze_ratio)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to open webcab to capture the image\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    _,frame = cap.read()\n",
    "    \n",
    "    #showing direction\n",
    "    new_frame = np.zeros((500,500,3),np.uint8)\n",
    "    \n",
    "    #change the color of the frame captured by webcam to grey\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # to detect faces from grey color frame\n",
    "    faces = detector(gray)\n",
    "    for face in faces:\n",
    "        \n",
    "        #to detect the landmarks of a face\n",
    "        landmarks = predictor(gray, face)\n",
    "        \n",
    "        left_eye_ratio = get_blinking_ratio([36, 37, 38, 39, 40, 41], landmarks)\n",
    "        right_eye_ratio = get_blinking_ratio([42, 43, 44, 45, 46, 47], landmarks)\n",
    "        blinking_ratio = (left_eye_ratio + right_eye_ratio) / 2\n",
    "\n",
    "    \n",
    "        if blinking_ratio>5.7:\n",
    "            cv2.putText(frame, \"BLINKING\", (50, 150), font, 7, (255, 0, 0))\n",
    "            \n",
    "        \n",
    "        #threshold_eye = cv2.resize(threshold_eye,None ,fx = 5,fy = 5)\n",
    "        #eye = cv2.resize(gray_eye, None,fx = 5,fy = 5)\n",
    "        \n",
    "        gaze_ratio_left_eye = get_gaze_ratio([36, 37, 38, 39, 40, 41], landmarks)\n",
    "        gaze_ratio_right_eye = get_gaze_ratio([42, 43, 44, 45, 46, 47], landmarks)\n",
    "        \n",
    "        gaze_ratio = (gaze_ratio_right_eye + gaze_ratio_left_eye) / 2\n",
    "        \n",
    "        if gaze_ratio <= 1:\n",
    "            cv2.putText(frame, \"RIGHT\", (50, 100), font, 2, (0, 0, 255), 3)\n",
    "            new_frame[:] = (0, 0, 255) #blue\n",
    "        elif 1 < gaze_ratio < 1.7:\n",
    "            cv2.putText(frame, \"CENTER\", (50, 100), font, 2, (0, 0, 255), 3) #black\n",
    "        \n",
    "        else:\n",
    "            new_frame[:] = (255, 0, 0) #red\n",
    "            cv2.putText(frame, \"LEFT\", (50, 100), font, 2, (0, 0, 255), 3)\n",
    "            #cv2.putText(frame,str(gaze_ratio),(50,100),font, 2, (0,0,255), 3)\n",
    "    \n",
    "        \n",
    "        \n",
    "    cv2.imshow(\"Frame\",frame)\n",
    "    cv2.imshow(\"NEW_Frame\",new_frame)\n",
    "    \n",
    "    key = cv2.waitKey(1)\n",
    "    #close the webcam when escape key is pressed\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "ShubhangiDabral13..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
